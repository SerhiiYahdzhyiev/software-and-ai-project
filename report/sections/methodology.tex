\section{Methodology}

This section covers the details of technical solutions used in the project and
aims to provide an understanding of why certain decisions were made, certain
tools and technologies were used.

\subsection{High Level Overview}

From a high level perspective CodeGlass consists of three main components:

\begin{itemize}
    \item Browser Extension (front-end)
    \item Application Server (back-end)
    \item LLM (AI) Adapter
\end{itemize}

Their composition can be inspected on the following figure.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/hl-arch.png}
    \caption{This is an example image}
    \label{fig:hl}
\end{figure}

The main idea behind using separate component for back-end, instead of realizing
the interactions directly between the \emph{Extension} and \emph{LLM API}, is to
provide an easy way for user to extend the tool and modify it to suit their needs,
without need to extend and/or modify the \emph{Extension}, as browser extension
development introduces specific challenges. As an addition keeping sensitive data
(such as API keys) in the browser introduces additional implications related to
security.

The project also aims to allow users to self-host the whole setup in order to avoid
potential trust issues.

Due to the time-pressure all components were implemented in plain JavaScript,
without Typescript usage.

All code implementations were realized respecting SOLID \autocite{SOLID} principles.

\subsection{Extension}

Extension component is responsible for tracking user's text highlighting events.
It consists of content script, background worker and popup window.

This text highlighting event capturing mechanism is realized in the content script
using "mouseup" DOM \autocite{DOM} event and window.getSelection \autocite{GS}
method.

Once the event is captured event listener checks if user selection is not empty, if
so sends an internal message via chrome.runtime.sendMessage method to the background 
worker.

On receiving highlighted text Background worker sends two sequential HTTP
\autocite{HTTP} requests to the \emph{Application Server}. First one to the
`/isCode` endpoint to the application server to use LLM for determining if the
highlighted text is some kind of programming code or markup language that should be
analyzed. If server return `false` here the pipeline stops, otherwise the second
request is sent to obtain structured analysis summary payload, that extension
can render on the page inside the popover element.

The extension's source code is structured in the following way:
\begin{itemize}
    \item `api` directory hold all the functions and constants needed to
        communicate with the \emph{Application Server}.
    \item `content` directory holds the main content script code.
    \item `css` directory holds CSS styles files.
    \item `pages` directory holds HTML file for extension's pop-up page.
    \item `popover` directory holds functions and constants related to rendering
        popover element.
    \item `storage` directory holds function and constants needed for storing and
        retrieving values from chrome.storage.local.

    \item `background.js` is sort of an entry point for the background worker.
    \item `popup.js` file is a script for pop-up page.
    \item `manifest.json` is a main manifest file which defines the extension's
        metadata, permissions, scripts, and behaviors, serving as the central
        configuration for how the extension interacts with the browser.
\end{itemize}

\subsection{Application Server}

This component is realized with the help of Node.js \autocite{NODE} JavaScript
Runtime using Express.js library for writing HTTP servers. The component is
responsible for communications with LLM API's through the Adapter component (will
be described in the following subsection). It is extremely simple and minimalistic.
All code is kept in a single `index.js` file. Server exposes two endpoints: `/isCode`
and `/info`.

To run the server users are required to set up environment variables via `.env` file.
Repository has an example `.env` file. More detailed instructions can be found in the
README.

The API keys should also be set up in the `.env` file. This is not required for
adapter clients realized by the users (in theory they can put the api keys directly
in the adapter client code), but we recommend to adhere to the best practices.

\subsection{Adapter}

The \emph{Adapter} component is a class that encapsulates all the logic related to
composing prompts, submitting them to the LLM, process models responses,
preparing/sanitizing the outputs that will be sent as a response to the
\emph{Extension}.

This component utilizes Dependency Inversion principle. It accepts the \emph{Client}
object as an argument passed to the constructor. The \emph{Client} object is
a pretty simple plain JavaScript object that has to realize \emph{getResponse}
method. This method accepts a prompt as an argument and is responsible for handling
the actual sending of the prompt to the LLM API and returning the model answer.

All other related functionality is handled by the \emph{Adapter}. If users want to
use the preferred LLM or API (they can even self-host a model), they need only
implement the \emph{Client} object with one required \emph{getResponse} method, and
then pass it on the \emph{Adapter} instantiation in the \emph{Application Server}
`index.js` file (line:22).
